{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of 20200513 Keras進階技巧：Sequential 的另一種用法",
      "provenance": [],
      "collapsed_sections": [
        "OSew6gi3goiy"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUZA3OvtRzK-"
      },
      "source": [
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/3649/media/cifar-10.png\"\n",
        "  />\n",
        "  <center>Cifar 10 資料庫</center>\n",
        "  <center>圖片來源: https://www.kaggle.com/</center>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJMS8p3wfPXO"
      },
      "source": [
        "## 1: 切換 TensorFlow 版本至 2.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXNUanZvcwwZ"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRHFdNYAfWKJ"
      },
      "source": [
        "## 2: 載入套件及資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS5xFeQwe9Xu"
      },
      "source": [
        "# Import some useful packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Layers for FNN\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "# Layers for CNN\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "# For data preprocessing\n",
        "from tensorflow.keras import datasets\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8zYubaPfy-S"
      },
      "source": [
        "## 3: 資料前處理 (Data Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YleM4DH4NoOA"
      },
      "source": [
        "CIFAR 10 是包含 10 種類的彩色小圖資料集，每張圖的尺寸為 $32\\times32$\n",
        "\n",
        "10 個類別分別是：飛機、交通工具、鳥、貓、鹿、狗、青蛙、馬、船、卡車"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOAGjiPogF0w"
      },
      "source": [
        "讀取 CIFAR 10 資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c5EYPsuNThg"
      },
      "source": [
        "name_list = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITug7sp2TAr5",
        "outputId": "9ebb87c7-e4cd-440b-a71d-368c9cd29c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load CIFAR 10\n",
        "(X_train, y_train0), (X_test, y_test0) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize the range of featurs\n",
        "X_train = X_train / X_train.max()\n",
        "X_test = X_test / X_test.max()\n",
        "\n",
        "# One-hot encoding\n",
        "y_train = to_categorical(y_train0, 10)\n",
        "y_test = to_categorical(y_test0, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnRkalOEMx8U",
        "outputId": "98b192b3-4661-4b63-a03d-b2d2590b563f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        }
      },
      "source": [
        "idx = np.random.randint(X_train.shape[0])\n",
        "X_sample = X_train[idx]\n",
        "y_sample = y_train0[idx].squeeze()\n",
        "\n",
        "plt.imshow(X_sample)\n",
        "plt.title(name_list[y_sample])\n",
        "plt.axis('off');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swp6zTOST8gD"
      },
      "source": [
        "## 4: 建立用於分類 CIFAR 10 的卷積神經網路\n",
        "\n",
        "在這個部分，我們將逐步帶領大家建立經典的 CNN 模型 LeNet-5 的變形。\n",
        "\n",
        "LeNet-5 分成兩個部分，分別為卷積層與全連接層，兩部份之間是透過扁平層 (Flatten) ，將卷積層最後輸出的 2 維向量壓扁成 1 維向量。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGEAVln9TRwa"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# First convolutional block\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "# Second convolutional block\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "# Third convolutional block\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Fully-connected layers as a classfier\n",
        "model.add(Dense(units=256, activation='relu'))\n",
        "\n",
        "# Ouput layer: # of neurons = # of classes with softmax activation\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "floU0of05vJj",
        "outputId": "a4db1eeb-3e7d-4be5-dfa6-b2f2bbc9923a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 762,122\n",
            "Trainable params: 762,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWdFSj9OcYWl"
      },
      "source": [
        "### 編譯模型: 設定模型訓練時的設定\n",
        "\n",
        "- Optimizer: Stochastic Gradient Descent (SGD)\n",
        "- Loss: categorical cross-entropy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86fvl2DHcKwj"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(),\n",
        "              metrics=['categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zz5yHOzdUgv"
      },
      "source": [
        "### 訓練模型: 透過訓練來學習分類資料的函數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVdaaVOJcKrk",
        "outputId": "0d5c796c-884f-4abb-8434-782349c01946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=128, \n",
        "          epochs=3,\n",
        "          validation_data=(X_test, y_test)\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 1.7968 - categorical_accuracy: 0.3269 - val_loss: 1.5709 - val_categorical_accuracy: 0.4158\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 1.4435 - categorical_accuracy: 0.4726 - val_loss: 1.3988 - val_categorical_accuracy: 0.4825\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 1.2795 - categorical_accuracy: 0.5344 - val_loss: 1.2381 - val_categorical_accuracy: 0.5516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1289c377f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnuqnY1TLpgR"
      },
      "source": [
        "model.save_weights('LeNet5_CIFAR10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IJhvV_BSo9x"
      },
      "source": [
        "### 模型預測: 預測資料集的準確率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btoBDRueSokB",
        "outputId": "e67ad73a-76e6-405c-8a3d-900b3e43d957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# model.load_weights('LeNet5_CIFAR10.h5')\n",
        "\n",
        "score_train = model.evaluate(X_train, y_train)\n",
        "score_test = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Train Accuracy: {score_train[1]*100}')\n",
        "print(f'Test Accuracy: {score_test[1]*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2300 - categorical_accuracy: 0.5508\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2381 - categorical_accuracy: 0.5516\n",
            "Train Accuracy: 55.080002546310425\n",
            "Test Accuracy: 55.15999794006348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV_jjr02p6Uz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4PKj-iYp3EB",
        "outputId": "b730f650-ad7c-47d1-9ecb-a5c2d0f550ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f128895b860>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f128810a1d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f128895b5f8>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f128813b898>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f128810a588>,\n",
              " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f12800cff60>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f128895b668>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f128813bd68>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyxQIxGNp6-A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0G7lUOLHQEjr"
      },
      "source": [
        "## 5: 另一種使用 Sequential 建立模型的方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14YYzYYwcKpE"
      },
      "source": [
        "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
        "              MaxPool2D(),\n",
        "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
        "              MaxPool2D(),\n",
        "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
        "              GlobalAveragePooling2D()]\n",
        "\n",
        "FC_layers = [Dense(units=256, activation='relu'),\n",
        "             Dense(units=10, activation='softmax')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn7EzCCgqkDs",
        "outputId": "c0d196fc-61ab-4d6b-ce84-4f440240b006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "CNN_layers + FC_layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f122beeee80>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f122bec8fd0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f122bec8be0>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7f122bea6320>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f128be674e0>,\n",
              " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f128813b8d0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f12800d66a0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f122bea68d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvmVUw4krEJq",
        "outputId": "483f1d0a-381f-419a-9889-ace2e94fc64c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 762,122\n",
            "Trainable params: 762,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43XOpYqROKzD",
        "outputId": "9fc405a4-992e-4f00-bc0a-843110a06fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model_2 = Sequential(CNN_layers+FC_layers)\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 762,122\n",
            "Trainable params: 762,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Axv5GfyzRfMZ"
      },
      "source": [
        "####  與使用 `model.add` 建立模型的差異？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tmJIForZPlR"
      },
      "source": [
        "model_2.compile(loss='categorical_crossentropy', \n",
        "                optimizer=Adam(),\n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "model_2.load_weights('LeNet5_CIFAR10.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2cXnaV8FHy",
        "outputId": "f5db455e-88ae-4313-ae0e-d75317ea2d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "score_train = model_2.evaluate(X_train, y_train, batch_size=1024)\n",
        "score_test = model_2.evaluate(X_test, y_test, batch_size=1024)\n",
        "\n",
        "print(f'Train Accuracy: {score_train[1]*100}')\n",
        "print(f'Test Accuracy: {score_test[1]*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49/49 [==============================] - 3s 59ms/step - loss: 1.2300 - categorical_accuracy: 0.5508\n",
            "10/10 [==============================] - 1s 91ms/step - loss: 1.2381 - categorical_accuracy: 0.5516\n",
            "Train Accuracy: 55.080002546310425\n",
            "Test Accuracy: 55.15999794006348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5Vf7bbrQIQc"
      },
      "source": [
        "## 6: 遷移學習 (Transfer Learning) 中的 Layer Transfer 的技巧"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmOkvmGXLjMo",
        "outputId": "1509cb1d-3a3a-4af8-8bb8-0ed55add458a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load CIFAR 100\n",
        "(U_train, v_train0), (U_test, v_test0) = datasets.cifar100.load_data()\n",
        "\n",
        "# Normalize the range of featurs\n",
        "U_train = U_train / U_train.max()\n",
        "U_test = U_test / U_test.max()\n",
        "\n",
        "# One-hot encoding\n",
        "v_train = to_categorical(v_train0, 100)\n",
        "v_test = to_categorical(v_test0, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRjjVxyiYxi4"
      },
      "source": [
        "LeNet-5 for CIFAR-10 (model_2)\n",
        "```\n",
        "CNN_layers = [Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', name='Conv_1'),\n",
        "              MaxPool2D(),\n",
        "              Conv2D(128, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
        "              MaxPool2D(),\n",
        "              Conv2D(512, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
        "              GlobalAveragePooling2D()]\n",
        "\n",
        "FC_layers = [Dense(units=256, activation='relu'),\n",
        "             Dense(units=10, activation='softmax')]\n",
        "```\n",
        "\n",
        "LeNet-5 for CIFAR-100\n",
        "```\n",
        "# From LeNet-5 for CIFAR-10\n",
        "CNN_layers\n",
        "\n",
        "# New FC layers for CIFAR-100\n",
        "FC_layers_CF100 = [Dense(units=256, activation='relu'),\n",
        "                   Dense(units=128, activation='relu'),\n",
        "                   Dense(units=100, activation='softmax')]\n",
        "```\n",
        "CNN_layers 是跟人家**借**來的。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd-lSV5rSJYX"
      },
      "source": [
        "FC_layers_CF100 = [Dense(units=256, activation='relu'),\n",
        "                   Dense(units=128, activation='relu'),\n",
        "                   Dense(units=100, activation='softmax')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF_YvZpEZuGD",
        "outputId": "99d6ebbc-1b9f-4777-ea7b-2efbfb5f7e6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model_CF100 = Sequential(CNN_layers+FC_layers_CF100)\n",
        "model_CF100.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 805,348\n",
            "Trainable params: 805,348\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2_KcAk4Z2Pv"
      },
      "source": [
        "對照一下和 LeNet-5 for CIFAR-10 的差別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_nXlKyZ14h",
        "outputId": "54215a0e-41b3-44af-b01b-44a995227f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 762,122\n",
            "Trainable params: 762,122\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2tE6ef-a65s"
      },
      "source": [
        "### 遷移學習的訓練方式\n",
        "* Fine-tune: 新資料集的樣本數夠多，整個模型重新訓練\n",
        "* Frozen: 當新資料集的樣本數不夠多，凍結借來的部分，只針對新建立的神經網路層訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q1B1e96Z7p8"
      },
      "source": [
        "for layer in CNN_layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szhsRPIXbb0F",
        "outputId": "e03d0133-0bbb-4c83-a692-ffd7690b7222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model_CF100.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 805,348\n",
            "Trainable params: 177,124\n",
            "Non-trainable params: 628,224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu6OYc8PbfHA"
      },
      "source": [
        "model_CF100.compile(loss='categorical_crossentropy', \n",
        "                    optimizer=Adam(),\n",
        "                    metrics=['categorical_accuracy'])\n",
        "\n",
        "model_CF100.fit(U_train, v_train,\n",
        "                batch_size=128, \n",
        "                epochs=5,\n",
        "                validation_data=(U_test, v_test)\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlZsfofSb5k1"
      },
      "source": [
        "### 借來的神經網路 (的權重) 會如何變化？Frozen 的場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dOhdwRrdAwt",
        "outputId": "74930cc2-1e1f-42c1-e829-9c13cfe3f56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "score_train = model_2.evaluate(X_train, y_train)\n",
        "score_test = model_2.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Train Accuracy: {score_train[1]*100}')\n",
        "print(f'Test Accuracy: {score_test[1]*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2300 - categorical_accuracy: 0.5508\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2381 - categorical_accuracy: 0.5516\n",
            "Train Accuracy: 55.080002546310425\n",
            "Test Accuracy: 55.15999794006348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysYktss3dE4J"
      },
      "source": [
        "### 借來的神經網路 (的權重) 會如何變化？Fine-tune 的場合"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjCaXC6bb_n4",
        "outputId": "df29d78c-c3aa-469a-b9d9-46db699b8c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "for layer in CNN_layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_CF100.fit(U_train, v_train,\n",
        "                batch_size=128, \n",
        "                epochs=1,\n",
        "                validation_data=(U_test, v_test)\n",
        "                )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 4s 11ms/step - loss: 2.8103 - categorical_accuracy: 0.2912 - val_loss: 2.8271 - val_categorical_accuracy: 0.2843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f122a8d70f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tt8jWVgvqKm"
      },
      "source": [
        "model_CF100.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jYVEtgJvBIe",
        "outputId": "a1b9b095-a302-4fa9-8fa6-ab075ec62247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "score_train = model_2.evaluate(X_train, y_train)\n",
        "score_test = model_2.evaluate(X_test, y_test)\n",
        "\n",
        "print(f'Train Accuracy: {score_train[1]*100}')\n",
        "print(f'Test Accuracy: {score_test[1]*100}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2418 - categorical_accuracy: 0.5517\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 1.2495 - categorical_accuracy: 0.5498\n",
            "Train Accuracy: 55.16600012779236\n",
            "Test Accuracy: 54.979997873306274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G2pTHXGfnzl"
      },
      "source": [
        "使用 Layer Transfer 的注意事項\n",
        "1. 若目的不同 (如；分類總數不同)，則須重新定義不同的全連接層\n",
        "2. 若資料的輸入尺寸不同 (如：channel 數不同)，則也需針對輸入的部分調整"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-CXv-J_lhB-"
      },
      "source": [
        "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
        "\n",
        "* Xception\n",
        "* VGG16\n",
        "* VGG19\n",
        "* ResNet50\n",
        "* InceptionV3\n",
        "* InceptionResNetV2\n",
        "* MobileNet\n",
        "* DenseNet\n",
        "* NASNet\n",
        "\n",
        "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
        "\n",
        "但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVErcleXjv3R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N42q2ROQliX8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxVPVZ5j0Fk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSew6gi3goiy"
      },
      "source": [
        "## [NOT FINISHED] 遷移學習的實作，以 Class Activation Map (CAM) 為例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FViBYlTgfBG"
      },
      "source": [
        "FC_layers_new = [Dense(units=10, activation='softmax')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzGxm7Qyg3nY",
        "outputId": "8deb2388-55c5-4f32-c46b-24aea0fc1fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "classifier = Sequential(CNN_layers+FC_layers_new)\n",
        "classifier.compile(loss='categorical_crossentropy', \n",
        "                   optimizer=Adam(),\n",
        "                   metrics=['categorical_accuracy'])\n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 633,354\n",
            "Trainable params: 633,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVvocZANhKsv"
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          batch_size=128, \n",
        "          epochs=20,\n",
        "          validation_data=(X_test, y_test)\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN6CEmmehLgh",
        "outputId": "86a123f9-c313-4a96-9b5f-51ee943e802f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "CAM_model = Sequential(CNN_layers[:-1]+FC_layers_new)\n",
        "CAM_model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=Adam(),\n",
        "                  metrics=['categorical_accuracy'])\n",
        "CAM_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv_1 (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "Conv_2 (Conv2D)              (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "Conv_3 (Conv2D)              (None, 8, 8, 512)         590336    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             multiple                  5130      \n",
            "=================================================================\n",
            "Total params: 633,354\n",
            "Trainable params: 633,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMhzBmihx0L",
        "outputId": "ca719f81-6f33-4959-847c-8f3529833858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "from PIL import Image\n",
        "CAM = CAM_model.predict(X_train[idx:idx+1])[0, : ,: , y_sample]\n",
        "CAM.resize(X_sample.shape)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(X_sample)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(np.clip(CAM, 0.1, 1), 'gray_r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0ca6532160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM2fZGEAkSLe",
        "outputId": "52fa57b0-7abb-4f87-9e44-ddbb0962da01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "np.clip(CAM, 0.1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
              "        0.1       , 0.1       , 0.1       ],\n",
              "       [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
              "        0.1       , 0.1       , 0.1       ],\n",
              "       [0.12071457, 0.1       , 0.11357061, 0.1       , 0.1       ,\n",
              "        0.1       , 0.10532729, 0.1       ],\n",
              "       [0.10987107, 0.10232778, 0.1       , 0.1       , 0.10549945,\n",
              "        0.12811796, 0.12720664, 0.10187284],\n",
              "       [0.107051  , 0.13169208, 0.1       , 0.1       , 0.1       ,\n",
              "        0.1210372 , 0.12632339, 0.11793717],\n",
              "       [0.1       , 0.11684094, 0.10440911, 0.1       , 0.11002783,\n",
              "        0.11910338, 0.11852513, 0.10015   ],\n",
              "       [0.1133763 , 0.10758757, 0.11185651, 0.11523668, 0.1216599 ,\n",
              "        0.10326762, 0.1122153 , 0.1060672 ],\n",
              "       [0.11666509, 0.12236123, 0.12577349, 0.13925031, 0.12089453,\n",
              "        0.10160585, 0.10003033, 0.1       ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GyElQZBifTS"
      },
      "source": [
        "class_intensity = FC_layers_new[0].get_weights()[0][:, y_sample]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvt5gYO-jIPO",
        "outputId": "f5dad685-2978-41b7-bfa4-8e3341a75e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "CAM_model.predict(X_train[idx:idx+1]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 8, 8, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    }
  ]
}